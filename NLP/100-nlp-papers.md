
大元
http://masatohagiwara.net/100-nlp-papers/


------------
## 論文名
### 著者
### 概要
### 新規性・結果・なぜ通ったか
### 先行研究と比べてどこがすごい？
### 技術や手法のキモはどこ？
### 議論はある？
### アイデア
### 次に読むべき論文は？
### 次の研究トレンドを作れるような問題を提案しているかどうか（e.g. Taskonomy, ImageNet）
### デファクトスタンダードになるような手法を提案しているかどうか（e.g. ResNet, R-CNN）
### 参考

--------

# Automatic Text Summarization

(まだ途中までしか読んでいない)
## 論文名
Summarization beyond sentence extraction:
A probabilistic approach to sentence compression

2002年

http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.19.5237&rep=rep1&type=pdf
### 著者
Kevin Knight , Daniel Marcu
### 概要
- we focus on sentence compression
- compressions should be grammatical, and they should retain the most important pieces of information/
- We have presented corpus-based methods for attacking this problem,
### 新規性・結果・なぜ通ったか
### 先行研究と比べてどこがすごい？
### 技術や手法のキモはどこ？
### 議論はある？
### アイデア
### 次に読むべき論文は？
### 次の研究トレンドを作れるような問題を提案しているかどうか（e.g. Taskonomy, ImageNet）
### デファクトスタンダードになるような手法を提案しているかどうか（e.g. ResNet, R-CNN）
### 参考
