------------
## 論文名
### 著者
### 概要
### 新規性・結果・なぜ通ったか
### 先行研究と比べてどこがすごい？
### 技術や手法のキモはどこ？
### 議論はある？
### アイデア
### 次に読むべき論文は？
### 次の研究トレンドを作れるような問題を提案しているかどうか（e.g. Taskonomy, ImageNet）
### デファクトスタンダードになるような手法を提案しているかどうか（e.g. ResNet, R-CNN）
### 参考

------------
## 論文名
Improving Coreference Resolution by Learning Entity-Level Distributed
Representations
https://nlp.stanford.edu/pubs/clark2016improving.pdf
### 著者
### 概要

- the incorporation of entity-level information
    - features defined over clusters of mentions instead of mention pairs.
    - We present a neural network based coreference system that produces high-dimensional vector representations for pairs of coreference clusters.
### 新規性・結果・なぜ通ったか
### 先行研究と比べてどこがすごい？
### 技術や手法のキモはどこ？
### 議論はある？
### アイデア
### 次に読むべき論文は？
### 次の研究トレンドを作れるような問題を提案しているかどうか（e.g. Taskonomy, ImageNet）
### デファクトスタンダードになるような手法を提案しているかどうか（e.g. ResNet, R-CNN）
### 参考
