# 論文名
### 著者
### 学会名/ジャーナル名
### 論文へのリンク


## 概要
単一の360o画像からシーンの深度を推定する学習フレームワークを提案。ground truth depthを元に学習することが新規性である。そのために、3Dデータセットを再利用し、レンダリングによって360oデータセットを合成する。ただし、現状では室内ケース、一定の照明、no stitching artifactsである場合に限られる。

### 事前知識
今までの奥行き推定に関する最近の研究は、360°のコンテンツを無視した投影画像のみに焦点を当てており、現在はますます簡単に作成されています。
360oデータセットで直接訓練する必要があることを示していますが、取得は困難です

- この作業では、最近リリースされた大規模な3Dデータセットを再利用し、レンダリングによって360oに再設計することにより、真実の深さの注釈を使用して高品質の360oデータセットを取得することに伴う課題を回避します。

- コンピュータと3Dビジョンの基本的な課題の1つは、シーンの深さの推定です。

## アイデア
- 実際の360oデーたセットが作成されて、それを元に学習させることは主流になっていくはず
- 今回のケースは室内であったが、屋外などの異なるケースで新規性を生み出すことは可能？﻿

## 新規性・結果・なぜ通ったか
## 先行研究と比べてどこがすごい？
## 技術や手法のキモはどこ？
## 議論はある？
## 次に読むべき論文は？

## 次の研究トレンドを作れるような問題を提案しているかどうか（e.g. Taskonomy, ImageNet）
## デファクトスタンダードになるような手法を提案しているかどうか（e.g. ResNet, R-CNN）
