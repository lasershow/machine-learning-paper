# 論文名
Learning Visual Question Answering by Bootstrapping Hard Attention
### 著者
### 学会名/ジャーナル名
### 論文へのリンク


## 概要
特徴ベクトルの大きさに基づいてそのサブセットを選択するという、HardAttentionのための新しいアプローチを提案する。提案手法は、VQAデータ・セットで、SoftAttentionの結果を上回る。さらにこの手法は、ソフトアテンションに比べて、計算効率上の利点がある。

### アテンション
http://ksksksks2.hatenadiary.jp/entry/20160430/1462028071
一方、attention を用いたモデルでは、エンコーダーの隠れ層のうち、特定の入力単語やその周辺の単語にフォーカスしたベクトルをデコーダで用います。これにより、デコーダのある時点で必要な情報にフォーカスして使用することができ、入力文の長さに関係なくデコードを効率よく行うことができます。attention の利用方法も手法によりけりですが、すべてのベクトルを重み付けして利用する global attention や特定のベクトルのみを用いる local attention と呼ばれる方法に分けている提案もあります。


## 新規性・結果・なぜ通ったか
## 先行研究と比べてどこがすごい？
## 技術や手法のキモはどこ？
## 議論はある？
## 次に読むべき論文は？

## 次の研究トレンドを作れるような問題を提案しているかどうか（e.g. Taskonomy, ImageNet）
## デファクトスタンダードになるような手法を提案しているかどうか（e.g. ResNet, R-CNN）
